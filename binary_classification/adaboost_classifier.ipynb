{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:  Raphael Cousin\n",
    "\n",
    "Project: https://github.com/racousin/algorithms_basics_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Context:__\n",
    "\n",
    "* Data : $X \\in \\mathbb{R}^d$ \n",
    "\n",
    "\n",
    "* Classes : $Y \\in \\{-1,1\\}$\n",
    "\n",
    "* Classifier :\n",
    "$g^*(x) = \\left\\{\\begin{array}{ll}1 & if\\quad\\mathbb{P}(Y = 1 | X = x) >\\mathbb{P}(Y = -1 | X = x) \\\\-1 & else\\end{array}\\right.$\n",
    "\n",
    "* sample size: $n$\n",
    "\n",
    "* feature size : $p$\n",
    "\n",
    "__Rademacher complexity:__\n",
    "\n",
    "$R(\\mathcal{C}(X)) = \\frac{1}{n} \\mathbb{E}_\\sigma\\left[sup_{g\\in \\mathcal{C}} \\sum_{i=1}^{n}\\sigma_i g(X_i)\\right]$\n",
    "\n",
    "where $\\sigma \\quad iid$ from Rademacher distribution\n",
    "\n",
    "__ADABOOST:__\n",
    "\n",
    "exponential loss $\\varphi : x \\mapsto e^{-Y_ix}$\n",
    "\n",
    "* initialisation:\n",
    "\n",
    "classifier number $T\\in \\mathbb{N}$\n",
    "\n",
    "points weight $D_1(i) = \\frac{1}{n} \\forall i \\in [1,n]$\n",
    "\n",
    "$f_0 = 0$\n",
    "\n",
    "* iteration for t of 1 to n:\n",
    "\n",
    "choice of classifier $g_t \\in \\mathcal{C}$ wich as $\\epsilon_t = \\sum_{i=1}^n D_t(i) \\mathbb{1}_{g_t(X_i) \\neq Y_i} \\leq small$\n",
    "\n",
    "classifier weight $w_t \\in argmin_{w \\in \\mathbb{R}}\\frac{1}{n}\\sum_{i=1}^{n}\\varphi_i\\left(f_{t-1}(X_i) + wg_t(X_i)\\right)$\n",
    "\n",
    "normalization $Z_t = \\sum_{i = 1}^{n} D_t(i)\\varphi(-w_tg_t(X_i))$\n",
    "\n",
    "$D_{t + 1}(i) = \\frac{D_t(i)\\varphi(-w_tg_t(X_i))}{Z_t} \\forall i \\in [1, n]$\n",
    "\n",
    "* adaboost classifier\n",
    "\n",
    "$g_n^T = sign(f_T)$\n",
    "\n",
    "__Hypothesis:__\n",
    "\n",
    "$\\exists \\gamma > 0 \\quad \\forall t \\in [1,T] \\quad \\epsilon_t \\leq \\frac{1}{2} - \\gamma \\quad ps$\n",
    "\n",
    "__Results:__\n",
    "\n",
    "$\\epsilon_t \\leq e^{-2\\gamma^2T}$\n",
    "\n",
    "\n",
    "$\\mathbb{P}(Y\\neq g_n^T(X)) \\leq \\left((1 - 4\\gamma^2)(\\frac{1 + 2\\gamma}{1 - 2 \\gamma})^\\gamma\\right)^{T/2} + \\frac{4}{\\gamma} R(\\mathcal{C}(X)) + \\sqrt{\\frac{-log(\\gamma)}{2n}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.discriminant_analysis import LinearClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost(BaseEstimator, LinearClassifierMixin):\n",
    "    def __init__(self, T = 1, clf = None):\n",
    "        self.g = None\n",
    "        self.d = None\n",
    "        self.w = None\n",
    "        self.z = None\n",
    "        self.f = None\n",
    "        self.T = T;\n",
    "        self.clf = clf\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        if self.clf is None:\n",
    "            self.clf = DecisionTreeClassifier(max_depth = 1, random_state = 1);\n",
    "        eps = lambda x, g: (self.d * (g(x) != Y)).sum()\n",
    "        self.d = np.ones(X.size) / X.size\n",
    "        self.g = [0] * self.T\n",
    "        self.w = [0] * self.T\n",
    "        f = lambda x : 0\n",
    "        for i in range(self.T):\n",
    "            tmp = self.clf.fit(X, Y);\n",
    "            self.g[i] = lambda x : tmp.predict(x)\n",
    "            self.w = 0.5 *np.log((1-eps(X, self.g[i])) / eps(X, self.g[i]))\n",
    "            self.z = 2 * (eps(X, self.g[i])(1 - eps(X, self.g[i]))) ** 0.5\n",
    "            self.d = self.d * np.exp(-self.w[i] * Y * self.g[i](X))\n",
    "        \n",
    "            def f(x):\n",
    "                res = 0;\n",
    "                for i in range(self.T):\n",
    "                    res += self.w[i] * self.g[i](x)\n",
    "                return res;\n",
    "            self.f = f;\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        return X.dot(self.coef) + self.intercept\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1800,) (900,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fb40c2542bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#compute model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-4310b9b5758b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-4310b9b5758b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, g)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1800,) (900,) "
     ]
    }
   ],
   "source": [
    "#compute model\n",
    "ada = AdaBoost()\n",
    "ada.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2d plot function\n",
    "def plot_2dX_Y(X, Y, ax=plt):\n",
    "    X1 = X[Y == 1]\n",
    "    X2 = X[Y == -1]\n",
    "    ax.plot(X1[:, 0], X1[:, 1], \">\", label=\"Class 1\")\n",
    "    ax.plot(X2[:, 0], X2[:, 1], \"d\", label=\"Class 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot border from clf\n",
    "def plot_border(clf, data=None, num=500, label=None,ax=plt):\n",
    "    \"\"\"\n",
    "        Plot the frontiere f(x)=0 of the classifier clf within the same range as the one\n",
    "        of the data.\n",
    "        Input:\n",
    "            clf: binary classifier with a method decision_function\n",
    "            data: input data (X)\n",
    "            num: discretization parameter\n",
    "    \"\"\"\n",
    "    xmin, ymin = data.min(axis=0)\n",
    "    xmax, ymax = data.max(axis=0)\n",
    "    x, y = np.meshgrid(np.linspace(xmin, xmax, num), np.linspace(ymin, ymax))\n",
    "    z = np.fabs(clf.decision_function(np.c_[x.ravel(), y.ravel()])).reshape(x.shape)\n",
    "    zmin, zmax = z.min(), z.max()\n",
    "    ind = np.where((z-zmin)/(zmax-zmin) < 0.001)\n",
    "    ind_sort = np.argsort(y[ind])\n",
    "    ax.plot(x[ind][ind_sort], y[ind][ind_sort], label=label, linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(clf,X,Y):\n",
    "    \"\"\"\n",
    "        Input:\n",
    "            clf: binary classifier with a method predict_function\n",
    "            data: (X)\n",
    "            classes: (Y) consider that Y=1 is 'yes class' and Y=-1 is 'No class'\n",
    "    \"\"\"\n",
    "    pred = clf.predict(X)\n",
    "    TP = ((pred == 1) & (Y == 1)).sum()\n",
    "    TN = ((pred == -1) & (Y == -1)).sum()\n",
    "    FP = ((pred == 1) & (Y == -1)).sum()\n",
    "    FN = ((pred == -1) & (Y == 1)).sum()\n",
    "    accuracy = (TP + TN) / (TP + TN + FN + FP)\n",
    "    prec = TP/ (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1Score = 2*(recall * prec) / (recall + prec)\n",
    "    print('True Positive:',TP)\n",
    "    print('True Negative:',TN)\n",
    "    print('False Positive:',FP)\n",
    "    print('False Negative:',FN)\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', prec)\n",
    "    print('Recall:', recall)\n",
    "    print('F1 Score:', F1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data\n",
    "p = 2;\n",
    "n = 1000;\n",
    "mu1 = np.random.randn(p) * 5\n",
    "mu2 = np.random.randn(p) * 5\n",
    "A = np.random.rand(p,p)\n",
    "sigma1 = np.dot(A,A.transpose()) * 10\n",
    "A = np.random.rand(p,p)\n",
    "sigma2 = np.dot(A,A.transpose()) * 10\n",
    "\n",
    "n1 = np.random.randint(int(n*0.1),int(n*0.9));\n",
    "n2 = n - n1;\n",
    "X1 = np.random.multivariate_normal(size=n1,mean=mu1,cov=sigma1)\n",
    "X2 = np.random.multivariate_normal(size=n2,mean=mu2,cov=sigma2)\n",
    "\n",
    "Y1 = np.ones(n1)\n",
    "Y2 = -np.ones(n2)\n",
    "X = np.r_[X1, X2]\n",
    "Y = np.r_[np.ones(X1.shape[0]), -np.ones(X2.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train set and test set\n",
    "data = np.c_[X,Y]\n",
    "np.random.shuffle(data)\n",
    "X_train = data[:int(n *0.9),0:p]\n",
    "Y_train = data[:int(n *0.9),p]\n",
    "X_test = data[int(n *0.9):,0:p]\n",
    "Y_test = data[int(n *0.9):,p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot train\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plot_2dX_Y(X_train, Y_train,ax)\n",
    "plot_border(ada, X_train,ax = ax,label='mine')\n",
    "ax.set_title('train model')\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics train\n",
    "get_metrics(lr, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot test\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plot_2dX_Y(X_test, Y_test,ax)\n",
    "plot_border(ada, X_test,ax = ax,label='mine')\n",
    "ax.set_title('test model')\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics test\n",
    "get_metrics(lr, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
